{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImageCaptioning.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tobehonest/ImageCaptioning/blob/master/ImageCaptioning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8C81mord6Ptq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FO2u8B1x6UWo",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**First lets begin with defining some python functions that will be used in this project**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKsE8czp7cRD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGQHrDgu6cZv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_sentence(string):\n",
        "  return list(filter(lambda word: len(word) > 0, re.split('\\W+',string)))\n",
        "#First we will split the sentences into words using re.split\n",
        "#Then we will use a condition of len(x) > 0 to filter the values\n",
        "#Then we will form a list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a30Ar8bV64yR",
        "colab_type": "code",
        "outputId": "280f179f-3130-410b-fbc2-fa5b9bf9acf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#LEts check this function\n",
        "\n",
        "split_sentence('My name is pulkit')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['My', 'name', 'is', 'pulkit']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IH46Wuxx68re",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_vocabulary(train_captions):\n",
        "    ans = []\n",
        "    vocab = []\n",
        "    for item in train_captions:\n",
        "      for sentence in item:\n",
        "        y = split_sentence(sentence)\n",
        "        for word in y:\n",
        "          ans.append(word)\n",
        "    unique = set(ans)\n",
        "    for word in unique:\n",
        "      i=0\n",
        "      for check in ans:\n",
        "        if check==word:\n",
        "          i+=1\n",
        "      if i>=5:\n",
        "        vocab.append(word)\n",
        "    print(vocab)\n",
        "    return {token: index for index, token in enumerate(sorted(vocab))}\n",
        "  \n",
        "  # First we extract each word from the captions to ans\n",
        "  # We create a set that will contain only unique words\n",
        "  # We will count through all the words if count >= 5 , keep it in vocabulary\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdnzsbJI-R_5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def caption_tokens_to_indices(captions, vocab):\n",
        "  res = [[\n",
        "            [vocab[START]] + [vocab.get(word, vocab[UNK]) for word in split_sentence(sentence)] + [vocab[END]] \n",
        "              for sentence in sentences] for sentences in captions]\n",
        "    \n",
        "  return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cX7vE9J9-W0n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we will use this during training\n",
        "def batch_captions_to_matrix(batch_captions, pad_idx, max_len=None):\n",
        "    \"\"\"\n",
        "    `batch_captions` is an array of arrays:\n",
        "    [\n",
        "        [vocab[START], ..., vocab[END]],\n",
        "        [vocab[START], ..., vocab[END]],\n",
        "        ...\n",
        "    ]\n",
        "    Put vocabulary indexed captions into np.array of shape (len(batch_captions), columns),\n",
        "        where \"columns\" is max(map(len, batch_captions)) when max_len is None\n",
        "        and \"columns\" = min(max_len, max(map(len, batch_captions))) otherwise.\n",
        "    Add padding with pad_idx where necessary.\n",
        "    Input example: [[1, 2, 3], [4, 5]]\n",
        "    Output example: np.array([[1, 2, 3], [4, 5, pad_idx]]) if max_len=None\n",
        "    Output example: np.array([[1, 2], [4, 5]]) if max_len=2\n",
        "    Output example: np.array([[1, 2, 3], [4, 5, pad_idx]]) if max_len=100\n",
        "    Try to use numpy, we need this function to be fast!\n",
        "    \"\"\"\n",
        "\n",
        "    return matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPMHkkJvBNtP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_captions_to_indices()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}